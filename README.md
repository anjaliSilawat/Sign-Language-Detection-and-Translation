
# Sign Language Detection and Translation using Python & Machine Learning (Ultralytics YOLOv8, OpenCV, Pyttsx3)

This is a sign language detection and translation model built using 
[ultralytics](https://github.com/ultralytics/ultralytics)
& [OpenCV](https://github.com/opencv/opencv)

Our pre-trained model trained on custom dataset detects sign language for the 9 following labels:
<ul>
    <li>Hello</li>
    <li>I Love You</li>
    <li>Yes</li>
    <li>No</li>
    <li>Thanks</li>
    <li>Please</li>
    <li>How</li>
    <li>Name</li>
    <li>You</li>
</ul>

Based on the detected gestures, the app can construct meaningful sentences and play an audio ğŸ”Š of the sentences, thereby giving voice to individuals with determination ğŸ’ªğŸ».

## Installation

- Clone the repository

```git
    git clone https://github.com/anjaliSilawat/Sign-Language-Detection-and-Translation.git
    cd Sign-Language-Detection-and-Translation
```

- Create a virtual environment

```git 
    python -m venv venv
```

-Activate the Virtual Environment

```git
    venv\Scripts\activate

```

- Install the required python packages

```git 
    pip install -r ./requirements.txt
```

    
